{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d9cf815-74e7-4bc8-9273-67315c0fdb5c",
   "metadata": {},
   "source": [
    "## Kurze Beschreibung zu den Bearbeitungsschritten:\n",
    "\n",
    "\n",
    "srtm:\n",
    "1. Download der verschiedenen Kacheln über den jeweiligen Dienst\n",
    "2. Mergen in QGIS und exportieren und speichern.\n",
    "3. Spatial resolution an die des sat anpassen (Erst die sat Datei bearbeiten, da dies evtl. zu einer veränderung der sr führen kann!)\n",
    "\n",
    "sat:\n",
    "1. Mit GDAL gdalbuildvrt -separate rgb.vrt red.tif green.tif blue.tif\n",
    "2. Mit GDAL gdalwarp -co \"TILED=YES\" -co BLOCKXSIZE=256 -co BLOCKYSIZE=256 -t_srs EPSG:xxxx rgb.vrt name_translate.tif   <-- add -srcnodata \"0\" to delete black edges!\n",
    "3. In QGIS Laden und schauen ob es vernünftig dargestellt wird\n",
    "4. Aus QGIS exportieren und darauf achten das Haken bei \"wie dargestellt\" gesetzt ist\n",
    "5. Dieses skript drüber laufen lassen incl. des crop Teils. Anscheinend wird das Bild nur als .png vernünftig dargestellt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "breathing-luxury",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the needed libraries\n",
    "\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "from rasterio.mask import mask\n",
    "from rasterio.plot import show\n",
    "from matplotlib import pyplot as plt\n",
    "import progressbar\n",
    "import os\n",
    "import skimage\n",
    "from skimage import io\n",
    "from skimage.io import imsave\n",
    "from PIL import Image\n",
    "import os, os.path\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import progressbar\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-conducting",
   "metadata": {},
   "source": [
    "## Extraction of images as np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "certified-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file with rasterio\n",
    "#data_dem = rasterio.open(\"C:/Users/robin/Google Drive/BA/Wellmann SatImg/01b_DEM_SAT_pairs/DEM_Aletsch_Winter.tif\") #AletschAlpsWinter\n",
    "#data_sat = rasterio.open(\"C:/Users/robin/Google Drive/BA/Wellmann SatImg/01b_DEM_SAT_pairs/SAT_Aletsch_Winter.tif\") #AletschAlpsWinter\n",
    "\n",
    "#data_dem = rasterio.open(\"C:/Users/robin/Google Drive/BA/Wellmann SatImg/01b_DEM_SAT_pairs/DEM_Bernese_Alps_summer.tif\") #BerneseAlpsSummer\n",
    "#data_sat = rasterio.open(\"C:/Users/robin/Google Drive/BA/Wellmann SatImg/01b_DEM_SAT_pairs/SAT_Bernese_Alps_summer.tif\") #BerneseAlpsSummer\n",
    "\n",
    "#data_dem = rasterio.open(\"C:/Users/robin/Google Drive/BA/Wellmann SatImg/01b_DEM_SAT_pairs/DEM_Alps_Summer_3.tif\") #Alps3\n",
    "#data_sat = rasterio.open(\"C:/Users/robin/Google Drive/BA/Wellmann SatImg/01b_DEM_SAT_pairs/SAT_Alps_Summer_3.tif\") #Alps3\n",
    "\n",
    "#data_dem = rasterio.open(\"C:/Users/robin/Google Drive/BA/Wellmann SatImg/01b_DEM_SAT_pairs/DEM_Alps_Summer.tif\") #Alps1\n",
    "#data_sat = rasterio.open(\"C:/Users/robin/Google Drive/BA/Wellmann SatImg/01b_DEM_SAT_pairs/SAT_Alps_Summer.tif\") #Alps1\n",
    "\n",
    "#data_dem = rasterio.open(\"C:/Users/robin/Google Drive/BA/Wellmann SatImg/01b_DEM_SAT_pairs/DEM_Alps_Summer_2.tif\") #Alps2\n",
    "#data_sat = rasterio.open(\"C:/Users/robin/Google Drive/BA/Wellmann SatImg/01b_DEM_SAT_pairs/SAT_Alps_Summer_2.tif\") #Alps2\n",
    "\n",
    "\n",
    "\n",
    "#data_dem = rasterio.open(\"C:/Users/robin/Google Drive/BA/Wellmann SatImg/01b_DEM_SAT_pairs/DEM_Allgaeu_Summer.tif\") #AllgaeuSummer\n",
    "#data_sat = rasterio.open(\"C:/Users/robin/Google Drive/BA/Wellmann SatImg/01b_DEM_SAT_pairs/SAT_Allgaeu_Summer.tif\") #AllgaeuSummer\n",
    "\n",
    "#fp_dem = os.path.join('/mnt', 'd', 'sciebo', 'BSc_Fehling_landscape_Gen', 'dem_sat','DEM_Bernese_Alps_winter.tif') #Bernese Winter\n",
    "#fp_sat = os.path.join('/mnt', 'd', 'sciebo', 'BSc_Fehling_landscape_Gen', 'dem_sat','SAT_Bernese_Alps_Winter.tif') #Bernese Sinter\n",
    "\n",
    "#fp_modis = os.path.join('/mnt','c','Users','robin','sciebo','EarthExplorer', 'Nepal', 'test_modis.tif') #modis image generated in qgis\n",
    "\n",
    "\n",
    "#fp_sat = os.path.join('/mnt','c','Users','robin','sciebo','BSc_Fehling_Landscape_Gen','dem_sat','SAT_Aletsch_Winter.tif')\n",
    "#fp_cop_dem = os.path.join('/mnt','c','Users','robin','sciebo','EarthExplorer','eu_dem_epsg_3857.tif')\n",
    "\n",
    "#fp_cop_dem = r'/mnt/c/Users/robin/sciebo/BSc_Fehling_Landscape_Gen/01b_DEM_SAT_pairs/eu_wgs84.tif'\n",
    "\n",
    "#fp_sat_sentinel2a = os.path.join('/mnt','d','sciebo','BSc_Fehling_Landscape_Gen','Training Datasets','Nepal', 'HLSSentinel-2','1','sat','test_dtype','translated_epsg_3857.tif')\n",
    "#fp_dem_sentinel2a = os.path.join('/mnt','d','sciebo','BSc_Fehling_Landscape_Gen','Training Datasets','Nepal', 'HLSSentinel-2','1','srtm','merged_dem_3857.tif')\n",
    "\n",
    "#fp_sat_sentinel2a = os.path.join('/mnt','d','BSc_Fehling_Landscape_Gen','Training Datasets','Nepal','S2B','GRANULE','L2A','IMG_DATA','R10m','warped_exported.tif')\n",
    "#fp_dem_sentinel2a = os.path.join('/mnt','d','BSc_Fehling_Landscape_Gen','Training Datasets','Nepal','S2B','srtm','merged_3857_res_increase.tif')\n",
    "\n",
    "\n",
    "#fp_sat_sentinel2a = os.path.join('/mnt', 'd', 'BSc_Fehling_Landscape_Gen', 'Training Datasets', 'Himalaya', 'S2A', 'GRANULE', 'L2A', 'IMG_DATA', 'R10m', 'warped_exported.tif')\n",
    "#fp_dem_sentinel2a = os.path.join('/mnt', 'd', 'BSc_Fehling_Landscape_Gen', 'Training Datasets', 'Himalaya', 'srtm', 'merged10m.tif')\n",
    "\n",
    "#fp_sat_sentinel2a = os.path.join('/mnt', 'd', 'sciebo','BSc_Fehling_Landscape_Gen', 'Training Datasets', 'Oman', 'HLSSentinel','sat_merged_rgb_3857.tif')\n",
    "#fp_dem_sentinel2a = os.path.join('/mnt', 'd', 'sciebo','BSc_Fehling_Landscape_Gen', 'Training Datasets', 'Oman', 'srtm','merged_3857.tif')\n",
    "\n",
    "fp_sat = r'/mnt/veracrypt2/CGRE/raw/Himalaya10x10/warped_exported.tif'\n",
    "fp_dem = r'/mnt/veracrypt2/CGRE/raw/Himalaya10x10/merged10m.tif'\n",
    "\n",
    "data_sat = rasterio.open(fp_sat)\n",
    "data_dem = rasterio.open(fp_dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "psychological-fitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_bbox(data_sat, nx=5000, ny=5000):\n",
    "    \"\"\"Generate random bbox within domain size of images\n",
    "    \n",
    "    nx = int: cells in x-direction\n",
    "    ny = int: cells in y-direction\n",
    "    \"\"\"\n",
    "    # set bounds from sat image for now:\n",
    "    global_min_x = data_sat.bounds[0]\n",
    "    global_min_y = data_sat.bounds[1]\n",
    "    global_max_x = data_sat.bounds[2]\n",
    "    global_max_y = data_sat.bounds[3]\n",
    "\n",
    "    # get random location\n",
    "    min_x = np.random.randint(global_min_x, global_max_x-nx)\n",
    "    max_x = min_x + nx\n",
    "    min_y = np.random.randint(global_min_y, global_max_y-ny)\n",
    "    max_y = min_y + ny\n",
    "\n",
    "    \n",
    "    bbox = box(min_x, min_y, max_x, max_y)\n",
    "\n",
    "    geo = gpd.GeoDataFrame({'geometry': bbox}, index=[0])\n",
    "    \n",
    "    return geo\n",
    "\n",
    "def extract_images(data_sat, data_dem, geo):\n",
    "    \"\"\"Extract subimages from sat and dem\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the geometry coordinates\n",
    "    coords = getFeatures(geo)\n",
    "\n",
    "    # Clip the raster with the polygon\n",
    "    out_img_sat, out_transform_sat = mask(data_sat, shapes=coords, crop=True)\n",
    "    out_img_dem, out_transform_dtm = mask(data_dem, shapes=coords, crop=True)\n",
    "    \n",
    "    return out_img_sat, out_img_dem\n",
    "\n",
    "def getFeatures(gdf):\n",
    "    \"\"\"Function to parse features from GeoDataFrame in such a manner that rasterio wants them\"\"\"\n",
    "    import json\n",
    "    return [json.loads(gdf.to_json())['features'][0]['geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "atomic-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_and_reorder(out_img_sat, out_img_dem):\n",
    "    # remove edges\n",
    "    out_img_sat = out_img_sat[:,2:-2,2:-2] #orig: out_img_sat[:,2:-2,2:-2] \n",
    "    out_img_dem = out_img_dem[:,2:-2,2:-2]\n",
    "    # reorder axes\n",
    "    out_img_sat_reshape = np.moveaxis(out_img_sat, 0, -1)\n",
    "    out_img_dem_reshape = np.moveaxis(out_img_dem, 0, -1)\n",
    "    \n",
    "    return out_img_sat_reshape, out_img_dem_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dense-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://stackoverflow.com/questions/52486237/how-to-turn-off-skimage-warnings\n",
    "# else scikit image will display a warning for a lossy conversion of int16 to uint8 every time a picture is saved\n",
    "import imageio.core.util\n",
    "\n",
    "def ignore_warnings(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "imageio.core.util._precision_warn = ignore_warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "visible-title",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (1000 of 1000) |####################| Elapsed Time: 0:03:31 Time:  0:03:31\n"
     ]
    }
   ],
   "source": [
    "# Get the training images. Cut out random images from the srtm and the satellite images.\n",
    "\n",
    "fp_save_sat2 = r'/mnt/veracrypt2/CGRE/processed/processed_datasets/sat/out_img_%06d.png'      # path to sat directory\n",
    "fp_save_dem2 = r'/mnt/veracrypt2/CGRE/processed/processed_datasets/npy_dem/out_img_%06d.npy'  # path to dem directory\n",
    "n = 1000                                                                                      # Number of images one wants to extract\n",
    "\n",
    "for i in progressbar.progressbar(range(n)):\n",
    "    geo = generate_random_bbox(data_sat, nx=6200, ny=4700)                                    # nx and ny correspond to the sizes of the images\n",
    "    out_img_sat, out_img_dem = extract_images(data_sat, data_dem, geo)\n",
    "    out_img_sat_reshape, out_img_dem_reshape = reshape_and_reorder(out_img_sat, out_img_dem)\n",
    "    \n",
    "    imsave(fp_save_sat2%i, out_img_sat_reshape, check_contrast = False)                        # save the sat files as png\n",
    "    \n",
    "    np.save(fp_save_dem2 % i, out_img_dem_reshape)                                             #saving the dems into numpy array first because that \n",
    "                                                                                               # doesnt seem to be a problem and without it the images appear grey!\n",
    "    im_2 = np.load(r'/mnt/veracrypt2/CGRE/processed/processed_datasets/npy_dem/out_img_%06d.npy' % i ) # Load the numpy array \n",
    "    img_DEM = Image.fromarray(im_2[:,:,0])                                                     # Convert array to image wit Pillow\n",
    "    mpimg.imsave(r'/mnt/veracrypt2/CGRE/processed/processed_datasets/dem/out_img_%06d.png' % i, img_DEM, cmap='gist_earth' ) # Save images as png\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-constant",
   "metadata": {},
   "source": [
    "# trying to reshape the image so all have the same resolution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-immigration",
   "metadata": {},
   "source": [
    "## Remember to clean the directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "funky-action",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (1000 of 1000) |####################| Elapsed Time: 0:00:12 Time:  0:00:12\n"
     ]
    }
   ],
   "source": [
    "#Reshape the images, so that all of the have the same size\n",
    "\n",
    "# Here we get the min sizes of x and y from the image\n",
    "\n",
    "list_ = r'/mnt/veracrypt2/CGRE/processed/processed_datasets/sat/' \n",
    "path, dirs, files = next(os.walk(list_))                                              # https://stackoverflow.com/questions/2632205/how-to-count-the-number-of-files-in-a-directory-using-python\n",
    "\n",
    "\n",
    "length = len(files)\n",
    "shapes_dem = []\n",
    "shapes_sat = []\n",
    "for i in progressbar.progressbar(range(length)):\n",
    "\n",
    "   \n",
    "\n",
    "    \n",
    "    fp_dem = r'/mnt/veracrypt2/CGRE/processed/processed_datasets/dem/out_img_%06d.png' \n",
    "    fp_sat = r'/mnt/veracrypt2/CGRE/processed/processed_datasets/sat/out_img_%06d.png'     \n",
    "    \n",
    "    im_dem = io.imread(fp_dem %i)\n",
    "    im_sat = io.imread(fp_sat %i)\n",
    "    \n",
    "    shapes_dem.append(im_dem.shape)\n",
    "    shapes_sat.append(im_sat.shape)\n",
    "    \n",
    "x_dem = []\n",
    "y_dem = []\n",
    "x_sat = []\n",
    "y_sat = []\n",
    "\n",
    "for i in shapes_dem:\n",
    "    x_dem.append(i[0])\n",
    "    y_dem.append(i[1])\n",
    "for i in shapes_sat:\n",
    "    x_sat.append(i[0])\n",
    "    y_sat.append(i[1])\n",
    "    \n",
    "maxx_dem = max(x_dem)\n",
    "maxy_dem = max(y_dem)\n",
    "minx_dem = min(x_dem)\n",
    "miny_dem = min(y_dem)\n",
    "\n",
    "\n",
    "maxx_sat = max(x_sat)\n",
    "maxy_sat = max(y_sat)\n",
    "minx_sat = min(x_sat)\n",
    "miny_sat = min(y_sat)\n",
    "\n",
    "if minx_dem > minx_sat:\n",
    "    minx = minx_sat\n",
    "else:\n",
    "    minx = minx_dem\n",
    "    \n",
    "if miny_dem > miny_sat:\n",
    "    miny = miny_sat\n",
    "else:\n",
    "    miny = miny_dem\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "western-shannon",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (1000 of 1000) |####################| Elapsed Time: 0:03:51 Time:  0:03:51\n"
     ]
    }
   ],
   "source": [
    "# Now we reshape the images!\n",
    "\n",
    "for i in progressbar.progressbar(range(length)):\n",
    "    \n",
    "    fp_dem = r'/mnt/veracrypt2/CGRE/processed/processed_datasets/dem/out_img_%06d.png' \n",
    "    fp_sat = r'/mnt/veracrypt2/CGRE/processed/processed_datasets/sat/out_img_%06d.png'\n",
    "    \n",
    "    im_dem = io.imread(fp_dem %i)\n",
    "    im_sat = io.imread(fp_sat %i)\n",
    "    \n",
    "    im_dem_new = im_dem[:minx, :miny]\n",
    "    im_sat_new = im_sat[:minx, :miny]\n",
    "    \n",
    "    imsave(fp_dem %i, im_dem_new, check_contrast = False)\n",
    "    imsave(fp_sat %i, im_sat_new, check_contrast = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a0454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cobine The dataset for the training with pix2pix\n",
    "fp_combine = r'/mnt/veracrypt2/CGRE/pytorch-CycleGAN-and-pix2pix/datasets/combine_A_and_B.py'\n",
    "fp_path_a = r'/mnt/veracrypt/CGRE/processed/training_datasets/himalaya10x10/A'\n",
    "fp_path_b = r'/mnt/veracrypt/CGRE/processed/training_datasets/himalaya10x10/B'\n",
    "fp_path_ab = r'/mnt/veracrypt/CGRE/processed/training_datasets/himalaya10x10/AB'\n",
    "\n",
    "!python D:/CGRE/pytorch-CycleGAN-and-pix2pix/datasets/combine_A_and_B.py --fold_A {fp_path_a} --fold_B {fp_path_b} --fold_AB {fp_path_ab}"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "768bf4f798c4a6ab17f54e2a33a654b83de9ec814c69661bfec107f3c9acc268"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
